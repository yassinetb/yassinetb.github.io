---
layout: page
permalink: /reads-2024/
title: 
description:
nav: false
show: false
---

<div class="talks">
    <div class="header-bar">
        <h1>Interesting Reads of 2024</h1>
        <p>I often read cool articles, or watch great youtube videos. But they might not be great enough for me to add on my "Internet Favorites" section. So here they are, as well as some personal notes on them. 
        <br /><br />
        Who knows - maybe your mind is currently open for some fascination? Maybe you'll find something here...</p> 
    </div>
</div>

<br />

 * [Lessons from Peter Thiel](https://www.8vc.com/resources/lessons-from-peter-thiel). 
    * Don't divide attention
    * When hiring, value "skill acquisition potential", as opposed to pre-existing skill
    * "Being the winner means being in the 99.99-percentile. A winner at the top takes nearly everything, and only a pittance goes to the others — so being 99.99-percentile is worth an order of magnitude or two more than being just 98-percentile. If it’s 1am and you’ve already got something that is very good, this is why it’s worth spending the next couple of hours to make it amazing."
    * 5. "Use small details as indicators to point to the larger truth — and be alert when they point to conclusions you don’t like." Judge the quality of a restaurant by the quality of its toilet paper. If it got the cheapest toilet paper, you can be sure it got the cheapest out of many other things.  
    
* [Reflections on Palantir](https://nabeelqu.substack.com/p/reflections-on-palantir)
    * Excellent article on what makes Palantir a great company with a good work ethos.
    * I found the distinction between Forward Deployed Engineers (FDE) and and (PD) engineers super interesting. FDE do fast and dirty development, PD do the clean work but much slower. "The PD engineers then ‘productize’ what the FDEs build, and – more generally – build software that provides leverage for the FDEs to do their work better and faster.2"
    * "The critical case against Palantir seemed to be something like “you shouldn’t work on [morally gray] things, because sometimes this involves making morally bad decisions”. An example was immigration enforcement during 2016-2020, aspects of which many people were uncomfortable with. But it seems to me that ignoring [morally gray] entirely, and just disengaging with it, is also an abdication of responsibility. Institutions in [morally gray stuff] need to exist. The USA is defended by people with guns. The police have to enforce the law, and - in my experience - even people who are morally uncomfortable with some aspects of policing are quick to call the police if their own home has been robbed. Oil companies have to provide energy. Health insurers have to make difficult decisions all the time. Yes, there are unsavory aspects to all of these things. But do we just disengage from all of these institutions entirely, and let them sort themselves out?"

* [How to program in Computational and Neural Systems Began - John Hopfield](/assets/pdf/CNS%20Origins_complete.pdf)
    * An extraordinary essay about the origins of the Computational and Neural Systems program, which is the main inspiration for the Masters program I completed in "Neural Systems and Computation". It's so humbling and source of pride to realize that this wave of work has impacted my own life - as many of the students of Hopfield's legacy were my own professors. 
    * It's fascinating to see the amount of effort that was needed to open this line of work, teaching and research at Caltech. Today, it's most obvious that this field is relevant - but even at Caltech, it was met with a great deal of skepticism when it was first suggested. Fascinating to see how much Hopfield had to push... 
    * The last quote is nothing short of extraordinary: *"Moving the intellectual focus of a university is somewhat like moving a graveyard. In both case, you should expect little help from the inhabitants."

* [The Hardware Lottery](https://arxiv.org/abs/2009.06489)
    * "The Anna Karenina principle: "A deficiency in any one of a number of factors dooms an endeavour to failure". Despite our preference to believe algorithms succeed or fail in isolation, history tells us that most computer science breakthroughs follow the Anna Karenina principle. Successful breakthroughs are often distinguished from failures by benefiting from multiple criteria aligning serendipitously."
	* "Being too early is the same as being wrong"
    *  "While specialization makes deep neural networks more efficient, it also makes it far more costly to stray from accepted building blocks. It prompts the question of how much researchers will implicitly overfit to ideas that operationalize well on available hardware rather than take a risk on ideas that are not currently feasible. *What are the failure we still don't have the hardware and software to see as a success?* "
    * I'll also remember the idea that a likely reason why symbolic approaches to AI were so successful is the ease through which these were running on the available hardware at the time, as well as a community with well documented and functioning programming languages (PROLOG and LISP). Success of a technology always relies on availability, and *suitability* to other previously available technologies. 

* [How To Understand Things](https://nabeelqu.substack.com/p/understanding)
    * The Parables of Agassiz and from "Zen and the Art of Motorcycle Maintenance" are wonderful -
    "The point of both of these parables: nothing beats direct experience. Get the data yourself. You develop some basis in reality by getting some first-hand data, and reasoning up from there, versus starting with somebody else’s lossy compression of a messy, evolving phenomenon and then wondering why events keep surprising you."
    * "The photographer Robert Capa advised beginning photographers: “If your pictures aren't good enough, you're not close enough”. It is also good advice for understanding things. When in doubt, go closer."

